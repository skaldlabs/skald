# Node Environment
NODE_ENV=development

# Database
DATABASE_URL=postgres://postgres:password@localhost/skald2

# Redis
REDIS_HOST=localhost
REDIS_PORT=6379
CHANNEL_NAME=process_memo

# AWS (for production SQS)
USE_SQS=false
SQS_QUEUE_URL=your-sqs-queue-url
AWS_REGION=us-east-2

# Voyage AI (Embeddings)
VOYAGE_API_KEY=your-voyage-api-key

# LLM Configuration
# Choose your LLM provider: openai, anthropic, or local
LLM_PROVIDER=openai

# OpenAI (if using openai provider)
OPENAI_API_KEY=your-openai-api-key
OPENAI_MODEL=gpt-4o-mini

# Anthropic (if using anthropic provider)
ANTHROPIC_API_KEY=your-anthropic-api-key
ANTHROPIC_MODEL=claude-3-7-sonnet-20250219

# Local LLM (if using local provider)
# Works with: Ollama, LM Studio, vLLM, LocalAI, etc.
# Examples:
#   - Ollama: http://localhost:11434/v1
#   - LM Studio: http://localhost:1234/v1
#   - vLLM: http://localhost:8000/v1
LOCAL_LLM_BASE_URL=http://localhost:11434/v1
LOCAL_LLM_MODEL=llama3.1:8b
LOCAL_LLM_API_KEY=not-needed
